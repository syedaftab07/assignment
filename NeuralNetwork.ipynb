{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/Alphabets_data.csv')\n",
        "\n",
        "# Display key features of the dataset\n",
        "print(f\"Number of samples: {df.shape[0]}\")\n",
        "print(f\"Number of features: {df.shape[1] - 1}\")\n",
        "print(f\"Classes: {df['letter'].unique()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GnkHDhvjPt8",
        "outputId": "2a84d13c-2b34-4065-c7d4-320ac739cad7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 20000\n",
            "Number of features: 16\n",
            "Classes: ['T' 'I' 'D' 'N' 'G' 'S' 'B' 'A' 'J' 'M' 'X' 'O' 'R' 'F' 'C' 'H' 'W' 'L'\n",
            " 'P' 'E' 'V' 'Y' 'Q' 'U' 'K' 'Z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "# Convert class labels to numeric\n",
        "label_encoder = LabelEncoder()\n",
        "df['letter'] = label_encoder.fit_transform(df['letter'])\n",
        "\n",
        "# Split the data into features and target\n",
        "X = df.drop('letter', axis=1)\n",
        "y = df['letter']\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "u4W6eapOm9Er"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create the ANN model\n",
        "def create_model(layers=[64, 32], activation='relu', learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(layers[0], input_dim=X_train.shape[1], activation=activation))\n",
        "    for layer in layers[1:]:\n",
        "        model.add(Dense(layer, activation=activation))\n",
        "    model.add(Dense(len(np.unique(y)), activation='softmax'))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Manual Hyperparameter Tuning\n",
        "param_grid = {\n",
        "    'layers': [[64, 32], [128, 64], [128, 64, 32]],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'learning_rate': [0.001, 0.01]\n",
        "}\n",
        "\n",
        "best_params = None\n",
        "best_score = 0\n",
        "for layers in param_grid['layers']:\n",
        "    for activation in param_grid['activation']:\n",
        "        for learning_rate in param_grid['learning_rate']:\n",
        "            model = create_model(layers=layers, activation=activation, learning_rate=learning_rate)\n",
        "            model.fit(X_train, y_train, epochs=10, batch_size=8, verbose=0)\n",
        "            y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            if accuracy > best_score:\n",
        "                best_score = accuracy\n",
        "                best_params = {'layers': layers, 'activation': activation, 'learning_rate': learning_rate}\n",
        "\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train the final model with the best parameters\n",
        "model = create_model(layers=best_params['layers'], activation=best_params['activation'], learning_rate=best_params['learning_rate'])\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duWqsfEQpTx7",
        "outputId": "122b472d-3b24-4ccf-c823-cd8cc70f6e3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 0s 2ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "125/125 [==============================] - 0s 1ms/step\n",
            "Best parameters: {'layers': [128, 64], 'activation': 'relu', 'learning_rate': 0.001}\n",
            "Epoch 1/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 1.4389 - accuracy: 0.6114 - val_loss: 0.7867 - val_accuracy: 0.7735\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6629 - accuracy: 0.8092 - val_loss: 0.5450 - val_accuracy: 0.8453\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4917 - accuracy: 0.8566 - val_loss: 0.4389 - val_accuracy: 0.8698\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3921 - accuracy: 0.8856 - val_loss: 0.3555 - val_accuracy: 0.8980\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.3268 - accuracy: 0.9033 - val_loss: 0.3142 - val_accuracy: 0.9093\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9155 - val_loss: 0.2774 - val_accuracy: 0.9193\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.9276 - val_loss: 0.2593 - val_accuracy: 0.9212\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.2170 - accuracy: 0.9343 - val_loss: 0.2322 - val_accuracy: 0.9315\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1947 - accuracy: 0.9429 - val_loss: 0.2164 - val_accuracy: 0.9352\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1755 - accuracy: 0.9444 - val_loss: 0.2090 - val_accuracy: 0.9305\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9504 - val_loss: 0.1921 - val_accuracy: 0.9423\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9556 - val_loss: 0.1818 - val_accuracy: 0.9460\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.1348 - accuracy: 0.9584 - val_loss: 0.1667 - val_accuracy: 0.9473\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.1262 - accuracy: 0.9620 - val_loss: 0.1703 - val_accuracy: 0.9450\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1167 - accuracy: 0.9631 - val_loss: 0.1575 - val_accuracy: 0.9490\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.1058 - accuracy: 0.9667 - val_loss: 0.1574 - val_accuracy: 0.9515\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9689 - val_loss: 0.1607 - val_accuracy: 0.9467\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9689 - val_loss: 0.1467 - val_accuracy: 0.9540\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9722 - val_loss: 0.1499 - val_accuracy: 0.9495\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9747 - val_loss: 0.1512 - val_accuracy: 0.9515\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9759 - val_loss: 0.1456 - val_accuracy: 0.9532\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9774 - val_loss: 0.1451 - val_accuracy: 0.9540\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9779 - val_loss: 0.1422 - val_accuracy: 0.9517\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.1298 - val_accuracy: 0.9582\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.1385 - val_accuracy: 0.9565\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9819 - val_loss: 0.1490 - val_accuracy: 0.9520\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 0.1419 - val_accuracy: 0.9528\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9828 - val_loss: 0.1284 - val_accuracy: 0.9605\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 0.1291 - val_accuracy: 0.9580\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.1386 - val_accuracy: 0.9560\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.1381 - val_accuracy: 0.9590\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.1257 - val_accuracy: 0.9613\n",
            "Epoch 33/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0428 - accuracy: 0.9868 - val_loss: 0.1218 - val_accuracy: 0.9628\n",
            "Epoch 34/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.9887 - val_loss: 0.1250 - val_accuracy: 0.9622\n",
            "Epoch 35/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0389 - accuracy: 0.9885 - val_loss: 0.1423 - val_accuracy: 0.9595\n",
            "Epoch 36/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.1200 - val_accuracy: 0.9635\n",
            "Epoch 37/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9890 - val_loss: 0.1277 - val_accuracy: 0.9613\n",
            "Epoch 38/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.1355 - val_accuracy: 0.9588\n",
            "Epoch 39/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.1198 - val_accuracy: 0.9647\n",
            "Epoch 40/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.1373 - val_accuracy: 0.9590\n",
            "Epoch 41/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9919 - val_loss: 0.1260 - val_accuracy: 0.9607\n",
            "Epoch 42/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9919 - val_loss: 0.1291 - val_accuracy: 0.9617\n",
            "Epoch 43/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.1199 - val_accuracy: 0.9670\n",
            "Epoch 44/50\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.1314 - val_accuracy: 0.9607\n",
            "Epoch 45/50\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.1250 - val_accuracy: 0.9625\n",
            "Epoch 46/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.1325 - val_accuracy: 0.9622\n",
            "Epoch 47/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 0.1302 - val_accuracy: 0.9663\n",
            "Epoch 48/50\n",
            "500/500 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.1352 - val_accuracy: 0.9630\n",
            "Epoch 49/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.1262 - val_accuracy: 0.9647\n",
            "Epoch 50/50\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.1202 - val_accuracy: 0.9650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluation\n",
        "# Make predictions with the best model\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR1aamrIpbEi",
        "outputId": "708c4205-ccee-4515-b838-af848f72a7a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.965\n",
            "Precision: 0.9655570427215572\n",
            "Recall: 0.965\n",
            "F1 Score: 0.9650036348756832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieves high accuracy (96.5%) in correctly predicting alphabet categories from the test data, indicating robust performance across precision, recall, and F1 score metrics."
      ],
      "metadata": {
        "id": "SmPDfE5guR0t"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}